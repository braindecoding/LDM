"""
ğŸ¯ Demo: Brain Decoding LDM

Complete demo showing how to use the Brain LDM for brain decoding.
Shows data loading, model creation, training setup, and inference.
"""

import torch
import matplotlib.pyplot as plt
import numpy as np

from data_loader import load_fmri_data
from brain_ldm import create_brain_ldm


def demo_data_loading():
    """Demo data loading for brain decoding."""
    print("ğŸ“Š Demo: Data Loading for Brain Decoding")
    print("-" * 50)
    
    # Load fMRI data
    loader = load_fmri_data()
    
    # Get training data
    train_stimuli = loader.get_stimuli('train')  # (90, 784) - target images
    train_fmri = loader.get_fmri('train')        # (90, 3092) - input brain signals
    
    print(f"ğŸ§  fMRI signals: {train_fmri.shape}")
    print(f"ğŸ¨ Stimulus images: {train_stimuli.shape}")
    print(f"ğŸ“‹ Task: fMRI ({train_fmri.shape[1]}) â†’ Stimulus ({train_stimuli.shape[1]})")
    
    # Show data statistics
    print(f"\nğŸ“ˆ Data Statistics:")
    print(f"  fMRI range: [{train_fmri.min():.3f}, {train_fmri.max():.3f}]")
    print(f"  Stimulus range: [{train_stimuli.min():.3f}, {train_stimuli.max():.3f}]")
    
    return loader


def demo_model_architecture():
    """Demo model architecture."""
    print("\nğŸ—ï¸ Demo: Brain LDM Architecture")
    print("-" * 50)
    
    # Create model
    model = create_brain_ldm(fmri_dim=3092, image_size=28)
    
    print(f"ğŸ§  Brain LDM Components:")
    print(f"  1. fMRI Encoder: {sum(p.numel() for p in model.fmri_encoder.parameters()):,} params")
    print(f"  2. VAE: {sum(p.numel() for p in model.vae.parameters()):,} params")
    print(f"  3. U-Net: {sum(p.numel() for p in model.unet.parameters()):,} params")
    print(f"  Total: {sum(p.numel() for p in model.parameters()):,} params")
    
    print(f"\nğŸ”„ Architecture Flow:")
    print(f"  fMRI (3092) â†’ fMRI Encoder â†’ Features (512)")
    print(f"  Stimulus (784) â†’ VAE Encoder â†’ Latents (4Ã—7Ã—7)")
    print(f"  Latents + Features â†’ U-Net â†’ Denoised Latents")
    print(f"  Denoised Latents â†’ VAE Decoder â†’ Reconstructed Stimulus")
    
    return model


def demo_forward_pass():
    """Demo forward pass through the model."""
    print("\nâš¡ Demo: Forward Pass")
    print("-" * 50)
    
    # Create model and dummy data
    model = create_brain_ldm()
    batch_size = 4
    
    # Dummy inputs
    fmri_signals = torch.randn(batch_size, 3092)
    stimulus_images = torch.randn(batch_size, 784)
    
    print(f"ğŸ“¥ Input shapes:")
    print(f"  fMRI signals: {fmri_signals.shape}")
    print(f"  Stimulus images: {stimulus_images.shape}")
    
    # Test training step
    batch = {'fmri': fmri_signals, 'stimulus': stimulus_images}
    
    with torch.no_grad():
        # Training forward pass
        output = model.training_step(batch)
        print(f"\nğŸ”„ Training step:")
        print(f"  Loss: {output['loss']:.4f}")
        print(f"  fMRI features norm: {output['fmri_features_norm']:.4f}")
        print(f"  Latents norm: {output['latents_norm']:.4f}")
        
        # Generation forward pass
        generated_images = model.generate_from_fmri(fmri_signals, num_inference_steps=10)
        print(f"\nğŸ¨ Generation:")
        print(f"  Generated images: {generated_images.shape}")
        print(f"  Output range: [{generated_images.min():.3f}, {generated_images.max():.3f}]")


def demo_training_setup():
    """Demo training setup."""
    print("\nğŸš€ Demo: Training Setup")
    print("-" * 50)
    
    # Load data
    loader = load_fmri_data()
    
    # Create model
    model = create_brain_ldm()
    
    # Create DataLoader
    train_loader = loader.create_dataloader(
        split='train',
        batch_size=4,
        shuffle=True
    )
    
    print(f"ğŸ“Š Training setup:")
    print(f"  Training batches: {len(train_loader)}")
    print(f"  Batch size: 4")
    print(f"  Total training samples: {len(train_loader) * 4}")
    
    # Test one training iteration
    batch = next(iter(train_loader))
    print(f"\nğŸ”„ Sample batch:")
    print(f"  fMRI: {batch['fmri'].shape}")
    print(f"  Stimulus: {batch['stimulus'].shape}")
    print(f"  Labels: {batch['label'].shape}")
    
    # Test training step
    with torch.no_grad():
        output = model.training_step(batch)
        print(f"\nğŸ“ˆ Training step result:")
        print(f"  Loss: {output['loss']:.4f}")
    
    print(f"\nğŸ’¡ To start training:")
    print(f"  python train_brain_ldm.py")


def demo_inference():
    """Demo inference without trained model."""
    print("\nğŸ”® Demo: Inference (Untrained Model)")
    print("-" * 50)
    
    # Load data
    loader = load_fmri_data()
    
    # Create model
    model = create_brain_ldm()
    
    # Get test data
    test_data = loader.get_test_data()
    fmri_signals = test_data['fmri'][:4]  # First 4 test samples
    true_stimuli = test_data['stimulus'][:4]
    
    print(f"ğŸ§ª Test data:")
    print(f"  fMRI signals: {fmri_signals.shape}")
    print(f"  True stimuli: {true_stimuli.shape}")
    
    # Generate reconstructions (untrained model)
    with torch.no_grad():
        generated_images = model.generate_from_fmri(
            fmri_signals, 
            num_inference_steps=20
        )
    
    print(f"\nğŸ¨ Generated reconstructions:")
    print(f"  Shape: {generated_images.shape}")
    print(f"  Range: [{generated_images.min():.3f}, {generated_images.max():.3f}]")
    
    # Create visualization
    fig, axes = plt.subplots(2, 4, figsize=(12, 6))
    
    for i in range(4):
        # True stimulus
        true_img = true_stimuli[i].view(28, 28).numpy()
        axes[0, i].imshow(true_img, cmap='gray')
        axes[0, i].set_title(f'True {i}')
        axes[0, i].axis('off')
        
        # Generated stimulus (untrained)
        gen_img = generated_images[i, 0].numpy()
        axes[1, i].imshow(gen_img, cmap='gray')
        axes[1, i].set_title(f'Generated {i}')
        axes[1, i].axis('off')
    
    plt.suptitle('Brain Decoding Demo: True vs Generated (Untrained Model)', fontsize=14)
    plt.tight_layout()
    plt.savefig('demo_brain_decoding.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print(f"ğŸ’¾ Saved demo visualization to: demo_brain_decoding.png")
    print(f"âš ï¸ Note: Model is untrained, so reconstructions are random!")


def demo_complete_pipeline():
    """Demo complete pipeline overview."""
    print("\nğŸ”„ Demo: Complete Pipeline Overview")
    print("-" * 50)
    
    print(f"ğŸ§  Brain Decoding LDM Pipeline:")
    print(f"")
    print(f"1. ğŸ“Š Data Loading:")
    print(f"   - Load fMRI signals (3092 voxels)")
    print(f"   - Load stimulus images (28Ã—28 pixels)")
    print(f"   - Create train/test splits")
    print(f"")
    print(f"2. ğŸ—ï¸ Model Architecture:")
    print(f"   - fMRI Encoder: Brain signals â†’ Condition features")
    print(f"   - VAE: Images â†” Latent space")
    print(f"   - U-Net: Conditional diffusion in latent space")
    print(f"   - Scheduler: Controls diffusion process")
    print(f"")
    print(f"3. ğŸš€ Training:")
    print(f"   - Forward diffusion: Add noise to latents")
    print(f"   - Condition on fMRI features")
    print(f"   - Train U-Net to predict noise")
    print(f"   - Optimize with MSE loss")
    print(f"")
    print(f"4. ğŸ”® Inference:")
    print(f"   - Start with random noise")
    print(f"   - Iteratively denoise with fMRI conditioning")
    print(f"   - Decode final latents to images")
    print(f"")
    print(f"5. ğŸ“Š Evaluation:")
    print(f"   - Compare reconstructed vs true stimuli")
    print(f"   - Compute MSE, correlation, SSIM")
    print(f"   - Visualize results")


def main():
    """Main demo function."""
    print("ğŸ¯ Brain Decoding LDM Complete Demo")
    print("=" * 60)
    print("Demonstrating Latent Diffusion Model for Brain Decoding")
    
    try:
        # Run all demos
        loader = demo_data_loading()
        model = demo_model_architecture()
        demo_forward_pass()
        demo_training_setup()
        demo_inference()
        demo_complete_pipeline()
        
        print(f"\nğŸ‰ Demo Completed Successfully!")
        print("=" * 40)
        print(f"âœ… Data loader working")
        print(f"âœ… Model architecture ready")
        print(f"âœ… Training pipeline set up")
        print(f"âœ… Inference pipeline working")
        print(f"âœ… Visualization created")
        
        print(f"\nğŸš€ Next Steps:")
        print(f"  1. Train the model: python train_brain_ldm.py")
        print(f"  2. Evaluate results: python evaluate_brain_ldm.py")
        print(f"  3. Experiment with hyperparameters")
        print(f"  4. Try different architectures")
        
        print(f"\nğŸ“ Files created:")
        print(f"  - demo_brain_decoding.png")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
