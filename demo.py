"""
Simple demo script to showcase the Latent Diffusion Model implementation.
This script demonstrates the model architecture without requiring full training.
"""

import numpy as np
import json
from pathlib import Path

def load_fmri_data():
    """Load and inspect the fMRI data."""
    print("=" * 60)
    print("LATENT DIFFUSION MODEL FOR fMRI RECONSTRUCTION")
    print("=" * 60)
    print()
    
    print("ğŸ“Š Loading fMRI Data...")
    
    # Load the aligned data
    data_file = Path("outputs/alignment_ridge_20250527_070315_aligned_data.npz")
    
    if not data_file.exists():
        print("âŒ Data file not found. Please ensure the outputs folder contains the aligned data.")
        return None
    
    data = np.load(data_file)
    
    print(f"âœ… Data loaded successfully!")
    print(f"   ğŸ“ File: {data_file}")
    print(f"   ğŸ”‘ Keys: {list(data.keys())}")
    print()
    
    # Analyze data structure
    total_samples = 0
    for subject_key in data.keys():
        subject_data = data[subject_key]
        print(f"   ğŸ‘¤ {subject_key}: {subject_data.shape} (timepoints Ã— voxels)")
        total_samples += subject_data.shape[0]
    
    print(f"   ğŸ“ˆ Total samples: {total_samples}")
    print(f"   ğŸ§  Voxels per sample: {data[list(data.keys())[0]].shape[1]}")
    
    # Combine all data
    all_data = np.vstack([data[key] for key in data.keys()])
    
    print()
    print("ğŸ“ˆ Data Statistics:")
    print(f"   ğŸ“Š Combined shape: {all_data.shape}")
    print(f"   ğŸ“Š Mean: {np.mean(all_data):.4f}")
    print(f"   ğŸ“Š Std: {np.std(all_data):.4f}")
    print(f"   ğŸ“Š Min: {np.min(all_data):.4f}")
    print(f"   ğŸ“Š Max: {np.max(all_data):.4f}")
    
    return all_data


def demonstrate_model_architecture():
    """Demonstrate the model architecture and components."""
    print()
    print("ğŸ—ï¸  Model Architecture Overview:")
    print("-" * 40)
    
    # Load configuration
    try:
        import yaml
        with open('config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        
        vae_config = config['vae']
        diffusion_config = config['diffusion']
        
        print("ğŸ”§ VAE Configuration:")
        print(f"   ğŸ“¥ Input dimension: {vae_config['input_dim']} voxels")
        print(f"   ğŸ¯ Latent dimension: {vae_config['latent_dim']}")
        print(f"   ğŸ—ï¸  Hidden layers: {vae_config['hidden_dims']}")
        print(f"   âš–ï¸  Beta (KL weight): {vae_config['beta']}")
        print()
        
        print("ğŸŒŠ Diffusion Model Configuration:")
        print(f"   â° Timesteps: {diffusion_config['num_timesteps']}")
        print(f"   ğŸ“Š Model channels: {diffusion_config['model_channels']}")
        print(f"   ğŸ”„ Residual blocks: {diffusion_config['num_res_blocks']}")
        print(f"   ğŸ“ˆ Beta schedule: {diffusion_config['beta_schedule']}")
        print()
        
        # Calculate approximate model size
        vae_encoder_params = vae_config['input_dim'] * vae_config['hidden_dims'][0]
        for i in range(len(vae_config['hidden_dims']) - 1):
            vae_encoder_params += vae_config['hidden_dims'][i] * vae_config['hidden_dims'][i+1]
        vae_encoder_params += vae_config['hidden_dims'][-1] * vae_config['latent_dim'] * 2  # mu and logvar
        
        vae_decoder_params = vae_encoder_params  # Symmetric
        
        # Rough estimate for diffusion model
        diffusion_params = diffusion_config['model_channels'] * 4 * 3  # Rough estimate
        
        total_params = vae_encoder_params + vae_decoder_params + diffusion_params
        
        print("ğŸ“Š Estimated Model Size:")
        print(f"   ğŸ”¢ VAE parameters: ~{vae_encoder_params + vae_decoder_params:,}")
        print(f"   ğŸ”¢ Diffusion parameters: ~{diffusion_params:,}")
        print(f"   ğŸ”¢ Total parameters: ~{total_params:,}")
        
    except ImportError:
        print("âš ï¸  PyYAML not installed. Install with: pip install pyyaml")
        print("   Using default configuration display...")
        
        print("ğŸ”§ VAE Configuration (Default):")
        print("   ğŸ“¥ Input dimension: 3092 voxels")
        print("   ğŸ¯ Latent dimension: 256")
        print("   ğŸ—ï¸  Hidden layers: [1024, 512, 256]")
        print("   âš–ï¸  Beta (KL weight): 1.0")
        print()
        
        print("ğŸŒŠ Diffusion Model Configuration (Default):")
        print("   â° Timesteps: 1000")
        print("   ğŸ“Š Model channels: 128")
        print("   ğŸ”„ Residual blocks: 2")
        print("   ğŸ“ˆ Beta schedule: linear")


def demonstrate_training_pipeline():
    """Demonstrate the training pipeline."""
    print()
    print("ğŸš€ Training Pipeline Overview:")
    print("-" * 40)
    
    print("ğŸ“š Training Phases:")
    print("   1ï¸âƒ£  Data Loading & Preprocessing")
    print("      â€¢ Load aligned fMRI data from multiple subjects")
    print("      â€¢ Normalize data (zero mean, unit variance)")
    print("      â€¢ Split into train/validation/test sets")
    print("      â€¢ Create data loaders with batching")
    print()
    
    print("   2ï¸âƒ£  VAE Training")
    print("      â€¢ Encode fMRI data to latent space")
    print("      â€¢ Decode latent representations back to fMRI")
    print("      â€¢ Optimize reconstruction + KL divergence loss")
    print("      â€¢ Learn meaningful latent representations")
    print()
    
    print("   3ï¸âƒ£  Diffusion Model Training")
    print("      â€¢ Add noise to latent representations")
    print("      â€¢ Train model to predict and remove noise")
    print("      â€¢ Learn reverse diffusion process")
    print("      â€¢ Enable generation of new latent codes")
    print()
    
    print("   4ï¸âƒ£  Joint Optimization")
    print("      â€¢ Fine-tune both VAE and diffusion components")
    print("      â€¢ Balance reconstruction quality and generation")
    print("      â€¢ Monitor validation metrics for early stopping")
    print()
    
    print("ğŸ“Š Evaluation Metrics:")
    print("   â€¢ Correlation analysis (overall, voxel-wise, sample-wise)")
    print("   â€¢ Error metrics (MSE, RMSE, MAE, RÂ², SNR, PSNR)")
    print("   â€¢ Distribution metrics (KS test, JS divergence)")
    print("   â€¢ Spatial pattern preservation")


def demonstrate_usage():
    """Demonstrate how to use the model."""
    print()
    print("ğŸ’» Usage Examples:")
    print("-" * 40)
    
    print("ğŸƒ Quick Start:")
    print("   # Install dependencies")
    print("   pip install -r requirements.txt")
    print()
    print("   # Train and evaluate model")
    print("   python main.py --config config.yaml --mode both")
    print()
    
    print("ğŸ”§ Advanced Usage:")
    print("   # Train only")
    print("   python main.py --mode train")
    print()
    print("   # Evaluate existing model")
    print("   python main.py --mode evaluate --checkpoint path/to/model.pt")
    print()
    print("   # Custom configuration")
    print("   python main.py --config custom_config.yaml")
    print()
    
    print("ğŸ“ Output Files:")
    print("   â€¢ checkpoints/: Saved model weights")
    print("   â€¢ logs/: Training logs and metrics")
    print("   â€¢ visualizations/: Generated plots and analysis")
    print("   â€¢ evaluation_metrics_*.json: Detailed metrics")


def show_project_structure():
    """Show the project structure."""
    print()
    print("ğŸ“‚ Project Structure:")
    print("-" * 40)
    
    structure = """
LDM/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ data/
â”‚   â”‚   â””â”€â”€ ğŸ“„ fmri_data_loader.py      # Data loading & preprocessing
â”‚   â”œâ”€â”€ ğŸ“ models/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ vae_encoder_decoder.py   # VAE implementation
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ diffusion_model.py       # Diffusion model & scheduler
â”‚   â”‚   â””â”€â”€ ğŸ“„ latent_diffusion_model.py # Complete LDM
â”‚   â”œâ”€â”€ ğŸ“ training/
â”‚   â”‚   â””â”€â”€ ğŸ“„ trainer.py               # Training pipeline
â”‚   â””â”€â”€ ğŸ“ utils/
â”‚       â”œâ”€â”€ ğŸ“„ metrics.py               # Evaluation metrics
â”‚       â””â”€â”€ ğŸ“„ visualization.py         # Visualization tools
â”œâ”€â”€ ğŸ“ outputs/                         # fMRI data files
â”œâ”€â”€ ğŸ“„ config.yaml                      # Configuration
â”œâ”€â”€ ğŸ“„ main.py                         # Main execution script
â”œâ”€â”€ ğŸ“„ requirements.txt                # Dependencies
â”œâ”€â”€ ğŸ“„ test_implementation.py          # Test suite
â””â”€â”€ ğŸ“„ README.md                       # Documentation
    """
    
    print(structure)


def main():
    """Main demo function."""
    # Load and analyze data
    data = load_fmri_data()
    
    if data is not None:
        # Show model architecture
        demonstrate_model_architecture()
        
        # Show training pipeline
        demonstrate_training_pipeline()
        
        # Show usage examples
        demonstrate_usage()
        
        # Show project structure
        show_project_structure()
        
        print()
        print("ğŸ‰ Demo completed!")
        print()
        print("ğŸ“ Next Steps:")
        print("   1. Install dependencies: pip install -r requirements.txt")
        print("   2. Run tests: python test_implementation.py")
        print("   3. Start training: python main.py")
        print()
        print("ğŸ“š For more information, see README.md")
    
    else:
        print("âŒ Demo failed due to missing data files.")
        print("   Please ensure the outputs folder contains aligned fMRI data.")


if __name__ == "__main__":
    main()
